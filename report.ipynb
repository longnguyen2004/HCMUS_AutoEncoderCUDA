{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ad6677",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13928221",
   "metadata": {},
   "source": [
    "## Section 1: Problem Description\n",
    "\n",
    "### 1. Problem Statement\n",
    "This project builds an autoencoder for image reconstruction on the CIFAR-10 dataset.  \n",
    "An autoencoder learns to compress images and then reconstruct them back.  \n",
    "The main goal is to implement and speed up this process using CUDA on GPU, because CPU training is very slow for neural networks.\n",
    "\n",
    "### 2. CIFAR-10 Dataset Overview\n",
    "CIFAR-10 is a popular image dataset for computer vision tasks.\n",
    "\n",
    "- Total images: 60,000  \n",
    "- Image size: 32 × 32 pixels  \n",
    "- Color channels: 3 (RGB)  \n",
    "- Classes (10): airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck  \n",
    "- Training set: 50,000 images  \n",
    "- Test set: 10,000 images  \n",
    "\n",
    "Each image is stored as unsigned 8-bit values.\n",
    "\n",
    "**Data preprocessing**:\n",
    "- Pixel values are normalized from \\[0, 255\\] to \\[0, 1\\] by dividing by 255.\n",
    "- Labels are ignored during autoencoder training.\n",
    "- No data augmentation is applied.\n",
    "\n",
    "(Sample images from each class will be shown here.)\n",
    "\n",
    "### 3. Autoencoder Architecture\n",
    "The autoencoder has two main parts: an encoder and a decoder.  \n",
    "The encoder compresses the image into a smaller representation.  \n",
    "The decoder reconstructs the image from that representation.\n",
    "\n",
    "**Input size**: 32 × 32 × 3  \n",
    "**Latent size**: 8 × 8 × 128 = 8,192 features  \n",
    "**Output size**: 32 × 32 × 3  \n",
    "\n",
    "#### Encoder\n",
    "- Conv2D: 3 → 256 channels, kernel 3×3, padding 1  \n",
    "- ReLU  \n",
    "- MaxPool2D: 2×2 → output 16×16×256  \n",
    "- Conv2D: 256 → 128 channels, kernel 3×3, padding 1  \n",
    "- ReLU  \n",
    "- MaxPool2D: 2×2 → output 8×8×128  \n",
    "![Encoder](resources/Encoder.png)\n",
    "\n",
    "#### Decoder\n",
    "- Conv2D: 128 → 128 channels, kernel 3×3, padding 1  \n",
    "- ReLU  \n",
    "- UpSample2D: 2×2 → output 16×16×128  \n",
    "- Conv2D: 128 → 256 channels, kernel 3×3, padding 1  \n",
    "- ReLU  \n",
    "- UpSample2D: 2×2 → output 32×32×256  \n",
    "- Conv2D: 256 → 3 channels, kernel 3×3, padding 1  \n",
    "- No activation function in the last layer  \n",
    "\n",
    "The decoder mirrors the encoder structure to help image reconstruction.\n",
    "![Decoder](resources/Decoder.png)\n",
    "\n",
    "\n",
    "### 4. Project Objectives\n",
    "- **Performance**: Achieve large speedup using GPU compared to CPU (target >20×).  \n",
    "- **Learning**: Understand autoencoders, CUDA programming, and GPU optimization.  \n",
    "- **Quality**: Reconstruct CIFAR-10 images with low reconstruction loss.  \n",
    "- **Pipeline**: Use the trained encoder to extract features for later classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0353537",
   "metadata": {},
   "source": [
    "## Section 2: Implementation Phases\n",
    "\n",
    "### Phase 2.1: CPU Baseline Implementation\n",
    "\n",
    "#### Objectives\n",
    "- Build a correct autoencoder running on CPU.\n",
    "- Verify forward and backward passes work as expected.\n",
    "- Measure time and loss as a baseline before GPU optimization.\n",
    "- This phase is required to ensure correctness before moving to CUDA.\n",
    "\n",
    "#### Implementation Details\n",
    "\n",
    "##### Data Pipeline\n",
    "- Load CIFAR-10 data from binary files.\n",
    "- Each image consists of 1 label byte and 3072 image bytes (32×32×3).\n",
    "- Normalize pixel values from [0, 255] to [0, 1].\n",
    "- **Training uses only 1,000 images (~2% of CIFAR-10 training set)** to speed up CPU experiments.\n",
    "- **Testing uses the full 10,000-image test set**.\n",
    "\n",
    "##### Layer Implementations\n",
    "- **Conv2D**: 3×3 convolution with padding, implemented using nested CPU loops.\n",
    "- **ReLU**: Element-wise max(0, x).\n",
    "- **MaxPool2D**: 2×2 pooling with stride 2, take maximum value.\n",
    "- **UpSample2D**: Nearest-neighbor upsampling by factor 2.\n",
    "\n",
    "- **Forward pass**:  \n",
    "  Each layer first calls the `forward()` function of its previous layer.  \n",
    "  After the previous output is ready, the current layer computes its own output.\n",
    "\n",
    "- **Backward pass**:  \n",
    "  The execution order is reversed.  \n",
    "  Each layer calls the `backward()` function of the next layer first, then computes its own gradients.\n",
    "\n",
    "This design keeps the layer connections simple and makes debugging easier.\n",
    "\n",
    "##### Training Loop\n",
    "- Loop over epochs.\n",
    "- Shuffle the 1,000 training images each epoch.\n",
    "- For each image:\n",
    "  - Forward pass through encoder and decoder.\n",
    "  - Compute MSE loss.\n",
    "  - Backward pass.\n",
    "  - Update weights using SGD.\n",
    "- Save model parameters after each epoch.\n",
    "\n",
    "##### Key Code Snippets\n",
    "\n",
    "Convolution function signature:\n",
    "```\n",
    "void convolve_cpu(\n",
    "    float *dst,\n",
    "    const float *src,\n",
    "    const float *kernel,\n",
    "    int col,\n",
    "    int row,\n",
    "    int kernel_width\n",
    ");\n",
    "```\n",
    "\n",
    "Main training loop:\n",
    "```\n",
    "for (const auto& image : image_refs) {\n",
    "    input->setImage(image->data);\n",
    "    output->forward();\n",
    "    output->backward(learning_rate, nullptr);\n",
    "}\n",
    "```\n",
    "\n",
    "#### Results\n",
    "\n",
    "- **Training data**: 1,000 images (≈2% of CIFAR-10 training set).\n",
    "- **Test data**: Full 10,000-image CIFAR-10 test set.\n",
    "- **Reconstruction loss**:\n",
    "  - Training MSE loss ≈ **0.01**.\n",
    "  - Test MSE loss ≈ **0.01**.\n",
    "- This result is **surprising**, because the model was trained on a very small subset but still shows similar loss on the full test set.\n",
    "- Loss values are stable during evaluation.\n",
    "- Reconstructed images preserve overall structure but are blurry.\n",
    "- Total parameters: ~751,875, small enough for CPU memory.\n",
    "\n",
    "#### Key Takeaways\n",
    "- Even training on only 1,000 images, the autoencoder generalizes well in terms of MSE.\n",
    "- CPU performance is very slow, mainly due to convolution.\n",
    "- Conv2D is the main bottleneck.\n",
    "- These observations strongly motivate moving convolution and training to GPU."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
